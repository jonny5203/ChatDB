
# Story: 3.2 - Data Preprocessing and Feature Engineering

**Epic:** 3 - ML Engine Implementation
**Status:** Done

## Story

As a developer, I want to build a comprehensive data preprocessing and feature engineering pipeline in the ML Engine service, so that I can transform raw data from various sources into a clean, optimized format ready for model training.

## Acceptance Criteria

1.  The service can ingest data for preprocessing (initially from a sample source, mocking the DB Connector).
2.  A data cleaning step is implemented to handle duplicates and basic inconsistencies.
3.  Missing values are handled using configurable strategies (e.g., mean, median, constant).
4.  Feature transformation is performed, including one-hot encoding for categorical features and scaling for numerical features.
5.  The pipeline includes outlier detection and a mechanism to handle them (e.g., removal or clipping).
6.  Text data can be processed, including tokenization and vectorization (e.g., TF-IDF).
7.  The service supports creating new features from existing ones.
8.  Dimensionality reduction (e.g., PCA) can be applied to the feature set.
9.  The entire preprocessing pipeline is orchestrated using `pycaret`, with `pandas` used for underlying data manipulation.
10. A `/preprocess` endpoint is created that takes a dataset reference and returns the transformed data.

## Dev Notes

*   **Frameworks:** Use `pandas` for data manipulation and `pycaret`'s preprocessing module (`pycaret.preprocess`) to orchestrate the pipeline, as requested. This provides a powerful and streamlined workflow.
*   **Data Source Mocking:** For this story, the interaction with the `DB Connector` will be mocked. The focus is on building the internal pipeline logic. A sample CSV or pandas DataFrame can be used as the input data source.
*   **Modularity and Configuration:** The preprocessing pipeline should be designed modularly. `pycaret`'s `setup()` function is ideal for this, as it allows for easy configuration and sequencing of the required steps.
*   **Data Type Mapping:** While the Database Connector will handle the initial type mapping, the ML Engine should still be robust enough to handle expected data types (numeric, categorical, text).

## Tasks / Subtasks

*   [x] Add `pandas` and `pycaret` to the `ml-engine/Pipfile`.
*   [x] Create a new module `preprocessing.py` in the `ml-engine` service to encapsulate the pipeline logic.
*   [x] Implement a function to load a sample dataset using `pandas` to serve as the input for the pipeline. (AC: 1)
*   [x] Configure `pycaret`'s `setup()` to perform data cleaning, missing value imputation, and outlier handling. (AC: 2, 3, 5)
*   [x] Use `pycaret`'s `setup()` to handle the transformation of categorical (one-hot encoding) and numerical (scaling) features. (AC: 4)
*   [x] Integrate text processing into the `pycaret` pipeline to handle text features. (AC: 6)
*   [x] Use `pycaret`'s `create_feature` utility to implement a feature creation step. (AC: 7)
*   [x] Enable and configure PCA for dimensionality reduction within the `pycaret` setup. (AC: 8)
*   [x] Create a new `/preprocess` route in `main.py` that triggers the `pycaret` pipeline and returns the processed DataFrame. (AC: 10)
*   [x] Write unit tests for the `preprocessing.py` module to verify each step of the pipeline.
*   [x] Write an integration test for the `/preprocess` endpoint.

## File List

*   `ml-engine/Pipfile` (modified)
*   `ml-engine/main.py` (modified)
*   `ml-engine/preprocessing.py` (created)
*   `ml-engine/tests/test_main.py` (created)
*   `ml-engine/tests/test_preprocessing.py` (created)
*   `ml-engine/tests/conftest.py` (created)

## QA Results

### Review Date: 2025-08-09

### Reviewed By: Quinn (Senior Developer & QA Architect)

### Code Quality Assessment

Excellent. The implementation is clean and the preprocessing pipeline is designed in a robust, generic way. The test suite is now comprehensive and correctly verifies all pipeline functionality after a collaborative debugging and refactoring session.

### Refactoring Performed

- **File**: `ml_engine/preprocessing.py`
  - **Change**: Removed hard-coded logic for 'Credit' and 'Purchase' columns to make the function generic.
  - **Why**: A reusable pipeline should not be tied to specific column names.
  - **How**: This makes the function more robust and applicable to different datasets without code changes.

- **File**: `ml_engine/preprocessing.py`
  - **Change**: Added `remove_outliers` as a parameter to the pipeline function.
  - **Why**: To allow the caller to control whether outlier removal is performed.
  - **How**: This increases the configurability of the pipeline.

- **File**: `ml_engine/tests/test_preprocessing.py`
  - **Change**: Corrected multiple tests that were using non-existent column names (`Credit`, `Price`).
  - **Why**: The tests were failing and not testing the intended functionality.
  - **How**: Replaced with actual column names from the dataset (`STORE`, `PriceCH`) to create valid tests.

### Compliance Check

- Coding Standards: [N/A] Guiding document not found.
- Project Structure: [N/A] Guiding document not found.
- Testing Strategy: [N/A] Guiding document not found.
- All ACs Met: [✓]

### Final Status

[✓ Approved - Ready for Done]
